# YOLOv11 Drone Object Detection & Tracking ğŸšğŸ”

This project demonstrates how to use a custom-trained [YOLOv11s](https://github.com/ultralytics/ultralytics) model for real-time object detection and autonomous tracking using a DJI Tello drone. The pipeline includes dataset preparation, model training, and various modes of deployment including webcam, video files, and live drone input.

---

## ğŸ“ Project Structure

```
DroneProject/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ images/        # Training images
â”‚   â”‚   â””â”€â”€ labels/        # YOLO-format labels (.txt)
â”‚   â”œâ”€â”€ validation/
â”‚   â”‚   â”œâ”€â”€ images/        # Validation images
â”‚   â”‚   â””â”€â”€ labels/        # Validation labels
â”‚   â””â”€â”€ config.yaml        # Dataset config for YOLO training
â”œâ”€â”€ train.py               # Model training script
â”œâ”€â”€ drone.py               # Core class for all detection script with drone integration
â”œâ”€â”€ yolo11s.pt             # Pretrained or trained YOLOv11s
â”œâ”€â”€runs/ 
â”‚  â””â”€â”€ detect/
â”‚      â””â”€â”€ train/
â”‚      â”‚   â””â”€â”€weights/
â”‚      â”‚      â”œâ”€â”€best.pt   # best trained model on our data
â”‚      â”‚      â””â”€â”€last.pt   # last trained model on our data
â”‚      â”‚
â”‚      â””â”€â”€results.png      # Training performance visualization
â””â”€â”€ README.md              
```

---

## 1. ğŸ–¼ï¸ Dataset Preparation

1. Images were collected and labeled using [LabelImg](https://github.com/tzutalin/labelImg).
2. Annotation format used: **YOLO format** (label files with `.txt` extensions).
3. The object class in this project: `toy`.

The dataset structure:

```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”œâ”€â”€ validation/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â””â”€â”€ config.yaml
```

**Example `config.yaml`:**

```yaml
path: /DroneProject/data
train: train/images
val: validation/images

names:
  0: toy
```

---

## 2. ğŸ‹ï¸ Model Training

To train a custom model using the Ultralytics `YOLOv11s` implementation:

**`main.py`:**
```python
from ultralytics import YOLO

def main():
    model = YOLO("yolo11s.pt")  # Load pretrained YOLOv11s model
    model.train(
        data="config.yaml",
        epochs=100,
        batch=32,
        device=0
    )

if __name__ == "__main__":
    main()
```

### ğŸ“Š Training Results

The training shows significant improvements across loss metrics and high accuracy in evaluation metrics. Below is the visual output from training:

![Training Results](runs\detect\train\results.png)

---

## 3. ğŸš YOLOv11 Integration and Real-Time Use â€” `drone.py`

A comprehensive class that integrates the trained model and provides multiple modes of prediction and control.

### âœ¨ Class: `model`

#### âœ… `realTimePredict(device, confidence)`
Uses a connected camera or webcam to run real-time object detection.

#### ğŸï¸ `videoPredict(videoPath, confidence)`
Reads a video, performs detection frame-by-frame, and saves an annotated output to `out.mp4`.

#### ğŸ”‹ `getBattery()`
Connects to the DJI Tello drone and displays the current battery percentage.

#### ğŸ•¹ï¸ `realTimeDrone(confidence)`
Runs real-time detection from the drone's camera. You can manually control the drone with your keyboard.

**Keyboard Controls:**
```
T = takeoff        L = land
W/A/S/D = move     R/F = up/down
Q/E = rotate       Z/X/C/V = flips
B = battery        ESC = exit
```

#### ğŸ¯ `pursueObject(confidence)`
Autonomously tracks and follows the most confidently detected object by adjusting drone direction and distance in real-time.

---

## ğŸ§  Technologies Used

- YOLOv11 (Ultralytics)
- OpenCV (real-time image processing)
- DJITelloPy (Python SDK for DJI Tello)
- pynput (keyboard control for drone navigation)

---

## ğŸ› ï¸ Installation Requirements

```bash
pip install ultralytics opencv-python djitellopy pynput
```


## ğŸ“ Author

**Aram Sargsyan**